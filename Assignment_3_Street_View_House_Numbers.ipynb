{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Assignment 3 - Street View House Numbers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiuyechen/EAI6000/blob/master/Assignment_3_Street_View_House_Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGD-Vfytesxf",
        "colab_type": "text"
      },
      "source": [
        "# Street View House Numbers Dataset\n",
        "\n",
        "\n",
        "The [Street View House Numbers Dataset](https://www.openml.org/d/41081) contains 32-by-32 RGB images centered around a single digit of a house number appearing in Google Street View. Many of the images do contain some distractors at the sides. It consists of 10 classes, 1 for each digit. Digit '1' has label 0, '9' has label 8 and '0' has label 9. Your goal is to build a model that recognizes the correct digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FAlXkmFesxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "!pip install openml # Uncomment to run in Google Colab\n",
        "import openml as oml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import pickle\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBpDMv1Vesxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download Streetview data. Takes a while to download (5-10 min).\n",
        "SVHN = oml.datasets.get_dataset(41081)\n",
        "X, y, cats, attrs = SVHN.get_data(dataset_format='array',\n",
        "    target=SVHN.default_target_attribute)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNMKV-mo6uWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To save time, you can save the dataset to a Google drive, and load it quickly later\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open(\"drive/My Drive/SVHN.pkl\", \"wb\") as f:\n",
        "    pickle.dump(X, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(y, f, protocol=pickle.HIGHEST_PROTOCOL)   \n",
        "    pickle.dump(cats, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    pickle.dump(attrs, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNc6MBHe8t4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Uncomment to) Load SVHN dataset from Google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# with open(\"drive/My Drive/SVHN.pkl\", \"rb\") as f:\n",
        "#     X = pickle.load(f)\n",
        "#     y = pickle.load(f)\n",
        "#     cats = pickle.load(f)\n",
        "#     attrs = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC2877HRDqhV",
        "colab_type": "text"
      },
      "source": [
        "### What is the shape of the image data X? How many images are there? Explain why each image has 3072 values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPTaJNbUC35Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdbVIX_zatiS",
        "colab_type": "text"
      },
      "source": [
        "### You can use the following function to plot the first 10 images to get a sense of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzE3X5Etesxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plots image. Use grayscale=True for plotting grayscale images\n",
        "def plot_images(X, y, grayscale=False):\n",
        "    fig, axes = plt.subplots(1, len(X),  figsize=(10, 5))\n",
        "    if grayscale:\n",
        "        [ax.imshow(X[n].reshape(32, 32)/255, cmap='gray')\n",
        "         for n,ax in enumerate(axes)]\n",
        "    else:\n",
        "        [ax.imshow(X[n].reshape(32, 32, 3)/255) for n,ax in enumerate(axes)]\n",
        "    [ax.set_title((y[n]+1)) for n,ax in enumerate(axes)]\n",
        "    [ax.axis('off') for ax in axes]\n",
        "plot_images(X[0:10], y[0:10]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEOqfNn0WEWn",
        "colab_type": "text"
      },
      "source": [
        "### Next, we will convert the images to greyscale and normalize the data to fall within the range 0 to 1. Plot the first 10 images to verify that the conversion worked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0AZiyprYIeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YYnvhirbCM2",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate different linear models\n",
        "\n",
        "1. To save time, use a stratified 1% subsample of the data. Plot the distribution of the classes (as a histogram) for both the original data and the subsample to verify this was done correctly. (hint: a quick way to do it is to borrow the stratify option with sklearn.model_selection.train_test_split)\n",
        "2. Evaluate k-Nearest Neighbors, Logistic Regression and Linear SVM on this sample, using their default hyperparameter settings. Use cross-validation with 3 folds, output the training accuracy and test accuracy (feel free to reuse code from past assignments). [Time](https://stackoverflow.com/questions/1557571/how-do-i-get-time-of-a-python-programs-execution) how long execution takes.\n",
        "3. Discuss the results. Are they what you expected? Are the models over/underfitting? What should be done to improve the results?\n",
        "4. Now evaluate the same models using 3% of the data. Discuss the results. Is the run time what you expect? Which models perform better or worse than the 1% training? How can you explain this in terms of underfitting/overfitting?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE7B8vgFbu5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXQh7T4VuHCP",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate feed-forward neural network\n",
        "\n",
        "Counter-intuitively, even though the linear models above are slow, you can easily train the small neural network below with 100% of the data in very little time. Learn more about Google Colab if you're curious: https://research.google.com/colaboratory/faq.html \n",
        "1. Train a neural network on the full (100%) data. Start with a single hidden layer with 256 neurons, and the same output layer as this week's Fashion-MNIST lab. Evaluate the accuracy using an 80/20 train test split. How does it compare with the linear models?\n",
        "2. Plot the confusion matrix. Which digits are often confused with each other? \n",
        "3. Plot the first 15 correctly classified examples and the first 15 incorrectly classified examples, along with a bar plot of the predictions array. You can use the provided plotting functions. What sort of errors do you see? Are these indeed 'hard' examples that are easy to get wrong?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAqj4k1njcUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label+1,\n",
        "                                100*np.max(predictions_array),\n",
        "                                true_label+1),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([1,2,3,4,5,6,7,8,9,0],rotation=90)\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar([1,2,3,4,5,6,7,8,9,0], predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqEXUgyYuEVJ",
        "colab_type": "text"
      },
      "source": [
        "Bonus challenge: \n",
        "Can you improve the model performance from this first Keras model?\n",
        "If you wonder about how researchers get to 98% accuracy, here is a list of papers :)\n",
        "https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#5356484e "
      ]
    }
  ]
}